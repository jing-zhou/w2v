{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w2v.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPJdMn+CT9xotuTSJIifwOu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jing-zhou/w2v/blob/master/w2v.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFC5eO7Tx2Km"
      },
      "source": [
        "**1. Environment setup and library import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDCkjdq0X763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "825b24f8-b9ac-4a63-dda2-ace98d6453de"
      },
      "source": [
        "import random                           # Generates random numbers\n",
        "import os                               # Create directories, list files\n",
        "from zipfile import ZipFile\n",
        "from shutil import copyfile             # Copy files from Source to Destination\n",
        "from time import time\n",
        "import cv2                              # To flip images in data augmentation\n",
        "import matplotlib.pyplot as plt         # To save the images\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "!pip install Cython"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (3.0.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUS-FJcrrb56"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCfhpvFj9MVS"
      },
      "source": [
        "**2. Link Goggle Drive with Colab**\n",
        "\n",
        "Source : https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2tGThfv49-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2fd45b6-c549-43fe-d692-411bd4fbf5ed"
      },
      "source": [
        "# Check is Link to Drive is OK\n",
        "google = !if [ -d 'GDrive/' ]; then echo \"1\" ; else echo \"0\"; fi\n",
        "if (google[0] == '0' ):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/GDrive/')\n",
        "!if [ -d 'GDrive/' ]; then echo \"Connection to Google drive successful\" ; else echo \"Error to connect to Google drive\"; fi\n",
        "\n",
        "gdrive = \"GDrive/My Drive/corpus/segmented/\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection to Google drive successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGBs0YKYOQQA"
      },
      "source": [
        "**3. Train W2V with Gensim**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4lau8kPO9Le",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "0160b25d-6c9b-4089-ab8c-9b273ab1f19e"
      },
      "source": [
        "from gensim.models.word2vec import PathLineSentences\n",
        "import multiprocessing\n",
        "import gensim.models\n",
        "\n",
        "class MyCorpus:\n",
        "  def __init__(self, corpus_path):\n",
        "    self.cor_path = corpus_path\n",
        "    self.cor_list = os.listdir(corpus_path)\n",
        "  \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
        "\n",
        "  def __iter__(self):\n",
        "    for name in self.cor_list:\n",
        "      # filter hide file\n",
        "      if name.startswith('.'):\n",
        "        continue\n",
        "\n",
        "      print(name)\n",
        "      for line in PathLineSentences(self.cor_path + '/' + name):\n",
        "        # print(line)\n",
        "        # assume there's one document per line, tokens separated by whitespace\n",
        "        yield line\n",
        "\n",
        "sentences = MyCorpus(gdrive)\n",
        "model = gensim.models.Word2Vec(\n",
        "    sentences=sentences,\n",
        "    min_count=5,\n",
        "    vector_size=512,\n",
        "    compute_loss=True,\n",
        "    workers=multiprocessing.cpu_count())\n",
        "\"\"\"\n",
        "model = gensim.models.Word2Vec(\n",
        "    sentences=sentences,\n",
        "    min_count=1,\n",
        "    size=128,\n",
        "    window=5,\n",
        "    workers=multiprocessing.cpu_count(),\n",
        "    compute_loss=True,\n",
        "    hs=0,\n",
        "    sg=1,\n",
        "    seed=42,\n",
        "    iter=1\n",
        "    )\n",
        "\"\"\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seg_bxab_1600420891674\n",
            "seg_dxaa_1600420892913\n",
            "seg_cxab_1600420894008\n",
            "seg_dxaj_1600420894978\n",
            "seg_fxaa_1600420895595\n",
            "seg_cxal_1600420896674\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-e19ebdfc2d8d>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdrive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m model = gensim.models.Word2Vec(\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus_iterable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcorpus_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m             self.train(\n\u001b[1;32m    431\u001b[0m                 \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \"\"\"\n\u001b[1;32m    490\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         total_words, corpus_count = self.scan_vocab(\n\u001b[0m\u001b[1;32m    492\u001b[0m             corpus_iterable=corpus_iterable, corpus_file=corpus_file, progress_per=progress_per, trim_rule=trim_rule)\n\u001b[1;32m    493\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, progress_per, workers, trim_rule)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mcorpus_iterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLineSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         logger.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[0;34m(self, sentences, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m    568\u001b[0m                 )\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                 \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mtotal_words\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgr54ERCRxxL"
      },
      "source": [
        "**4. display the W2V**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKgeRmZcR7TH"
      },
      "source": [
        "for i, word in enumerate(model.wv.vocab):\n",
        "  if i == 10:\n",
        "    break\n",
        "  print(word)\n",
        "  print(model.wv[word])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpAF95gvTm-N"
      },
      "source": [
        "**5. Store the model file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AftqhQ6BTtub"
      },
      "source": [
        "models_dir = 'models'\n",
        "if not os.path.exists(models_dir):\n",
        "  os.mkdir(models_dir)\n",
        "\n",
        "model.save(models_dir + '/model_' + str(int(time()*1000)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7AOOqZ1F5P6"
      },
      "source": [
        "**7. Demo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN6gM9PqGBVA"
      },
      "source": [
        "print('%r\\t%r\\t%.2f' % (\"维蒂格豪森\", \"迪欣根\", model.similarity(\"维蒂格豪森\", \"迪欣根\")))\n",
        "\n",
        "print('%r\\t%r\\t%.2f' % (\"中華民國\", \"迪欣根\", model.similarity(\"中華民國\", \"迪欣根\")))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}