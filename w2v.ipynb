{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w2v.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN03rbuz0j7YMTZaTQtc5gh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jing-zhou/w2v/blob/master/w2v.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFC5eO7Tx2Km"
      },
      "source": [
        "**1. Environment setup and library import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDCkjdq0X763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3596a7e3-5d75-49f1-cffd-8b7fb160c694"
      },
      "source": [
        "import random                           # Generates random numbers\n",
        "import os                               # Create directories, list files\n",
        "from zipfile import ZipFile\n",
        "from shutil import copyfile             # Copy files from Source to Destination\n",
        "from time import time\n",
        "import cv2                              # To flip images in data augmentation\n",
        "import matplotlib.pyplot as plt         # To save the images\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "!pip install Cython"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (3.0.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUS-FJcrrb56"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCfhpvFj9MVS"
      },
      "source": [
        "**2. Link Goggle Drive with Colab**\n",
        "\n",
        "Source : https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2tGThfv49-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204ba22b-5911-4fe0-df13-5b5d13f7e1a4"
      },
      "source": [
        "# Check is Link to Drive is OK\n",
        "google = !if [ -d 'GDrive/' ]; then echo \"1\" ; else echo \"0\"; fi\n",
        "if (google[0] == '0' ):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/GDrive/')\n",
        "!if [ -d 'GDrive/' ]; then echo \"Connection to Google drive successful\" ; else echo \"Error to connect to Google drive\"; fi\n",
        "\n",
        "gdrive = \"GDrive/My Drive/corpus/segmented/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection to Google drive successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGBs0YKYOQQA"
      },
      "source": [
        "**3. Train W2V with Gensim**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4lau8kPO9Le",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f17be5b9-79f0-48df-9cae-b7ac202b4682"
      },
      "source": [
        "from gensim.models.word2vec import PathLineSentences\n",
        "import multiprocessing\n",
        "import gensim.models\n",
        "\n",
        "class MyCorpus:\n",
        "  def __init__(self, corpus_path):\n",
        "    self.cor_path = corpus_path\n",
        "    self.cor_list = os.listdir(corpus_path)\n",
        "  \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
        "\n",
        "  def __iter__(self):\n",
        "    for name in self.cor_list:\n",
        "      # filter hide file\n",
        "      if name.startswith('.'):\n",
        "        continue\n",
        "\n",
        "      print(name)\n",
        "      for line in PathLineSentences(self.cor_path + '/' + name):\n",
        "        # print(line)\n",
        "        # assume there's one document per line, tokens separated by whitespace\n",
        "        yield line\n",
        "\n",
        "sentences = MyCorpus(gdrive)\n",
        "model = gensim.models.Word2Vec(\n",
        "    sentences=sentences,\n",
        "    iter=5,\n",
        "    min_count=5,\n",
        "    vector_size=512,\n",
        "    compute_loss=True,\n",
        "    workers=multiprocessing.cpu_count())\n",
        "\"\"\"\n",
        "model = gensim.models.Word2Vec(\n",
        "    sentences=sentences,\n",
        "    min_count=1,\n",
        "    size=128,\n",
        "    window=5,\n",
        "    workers=multiprocessing.cpu_count(),\n",
        "    compute_loss=True,\n",
        "    hs=0,\n",
        "    sg=1,\n",
        "    seed=42,\n",
        "    iter=1\n",
        "    )\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seg_bxab_1600420891674\n",
            "seg_dxaa_1600420892913\n",
            "seg_cxab_1600420894008\n",
            "seg_dxaj_1600420894978\n",
            "seg_fxaa_1600420895595\n",
            "seg_cxal_1600420896674\n",
            "seg_exae_1600420897586\n",
            "seg_bxae_1600420898825\n",
            "seg_exag_1600420899885\n",
            "seg_bxac_1600420901018\n",
            "seg_axal_1600420902316\n",
            "seg_dxai_1600420903234\n",
            "seg_exaf_1600420903664\n",
            "seg_exaj_1600420904714\n",
            "seg_axaa_1600420905944\n",
            "seg_axar_1600420907343\n",
            "seg_axag_1600420908031\n",
            "seg_fxac_1600420909006\n",
            "seg_bxad_1600420910165\n",
            "seg_cxae_1600420911294\n",
            "seg_cxai_1600420912337\n",
            "seg_exab_1600420913338\n",
            "seg_exaa_1600420913771\n",
            "seg_dxag_1600420914627\n",
            "seg_bxaa_1600420915406\n",
            "seg_cxag_1600420916450\n",
            "seg_cxaa_1600420917469\n",
            "seg_axac_1600420918291\n",
            "seg_bxak_1600420919325\n",
            "seg_bxal_1600420920287\n",
            "seg_dxah_1600420921374\n",
            "seg_axai_1600420922073\n",
            "seg_dxae_1600420923040\n",
            "seg_exah_1600420923948\n",
            "seg_exac_1600420925168\n",
            "seg_fxah_1600420925840\n",
            "seg_cxaj_1600420926697\n",
            "seg_bxai_1600420927726\n",
            "seg_dxad_1600420928760\n",
            "seg_bxaf_1600420929255\n",
            "seg_bxaj_1600420930323\n",
            "seg_cxad_1600420931322\n",
            "seg_fxab_1600420932242\n",
            "seg_axaj_1600420933400\n",
            "seg_exad_1600420934329\n",
            "seg_cxan_1600420935385\n",
            "seg_exai_1600420935682\n",
            "seg_axad_1600420936947\n",
            "seg_cxak_1600420938127\n",
            "seg_axan_1600420939100\n",
            "seg_axae_1600420939931\n",
            "seg_fxad_1600420941002\n",
            "seg_cxam_1600420942280\n",
            "seg_dxab_1600420943279\n",
            "seg_cxac_1600420943773\n",
            "seg_axas_1600420944816\n",
            "seg_fxaf_1600420945514\n",
            "seg_axah_1600420946609\n",
            "seg_axao_1600420947523\n",
            "seg_cxaf_1600420948449\n",
            "seg_axaf_1600420949413\n",
            "seg_bxam_1600420950315\n",
            "seg_fxae_1600420951253\n",
            "seg_bxah_1600420952272\n",
            "seg_bxan_1600420953383\n",
            "seg_axaq_1600420953532\n",
            "seg_bxag_1600420954333\n",
            "seg_axap_1600420955324\n",
            "seg_axam_1600420956210\n",
            "seg_dxaf_1600420957073\n",
            "seg_axak_1600420957903\n",
            "seg_fxag_1600420959051\n",
            "seg_cxah_1600420960195\n",
            "seg_dxac_1600420961134\n",
            "seg_axab_1600420961844\n",
            "seg_axat_1600420962921\n",
            "seg_bxab_1600420891674\n",
            "seg_dxaa_1600420892913\n",
            "seg_cxab_1600420894008\n",
            "seg_dxaj_1600420894978\n",
            "seg_fxaa_1600420895595\n",
            "seg_cxal_1600420896674\n",
            "seg_exae_1600420897586\n",
            "seg_bxae_1600420898825\n",
            "seg_exag_1600420899885\n",
            "seg_bxac_1600420901018\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ff7d8128376c>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdrive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m model = gensim.models.Word2Vec(\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             self.train(\n\u001b[0m\u001b[1;32m    431\u001b[0m                 \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcorpus_iterable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[0m\u001b[1;32m   1074\u001b[0m                     \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                     \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m   1432\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[0m\u001b[1;32m   1435\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_corpus_file_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgr54ERCRxxL"
      },
      "source": [
        "**4. display the W2V**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKgeRmZcR7TH"
      },
      "source": [
        "for i, word in enumerate(model.wv.vocab):\n",
        "  if i == 10:\n",
        "    break\n",
        "  print(word)\n",
        "  print(model.wv[word])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpAF95gvTm-N"
      },
      "source": [
        "**5. Store the model file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AftqhQ6BTtub"
      },
      "source": [
        "models_dir = 'models'\n",
        "if not os.path.exists(models_dir):\n",
        "  os.mkdir(models_dir)\n",
        "\n",
        "model.save(models_dir + '/model_' + str(int(time()*1000)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7AOOqZ1F5P6"
      },
      "source": [
        "**7. Demo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN6gM9PqGBVA"
      },
      "source": [
        "print('%r\\t%r\\t%.2f' % (\"维蒂格豪森\", \"迪欣根\", model.similarity(\"维蒂格豪森\", \"迪欣根\")))\n",
        "\n",
        "print('%r\\t%r\\t%.2f' % (\"中華民國\", \"迪欣根\", model.similarity(\"中華民國\", \"迪欣根\")))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}